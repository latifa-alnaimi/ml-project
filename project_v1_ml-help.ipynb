{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project\n",
    "\n",
    "### Solution by: *Latifa Al-Naimi* \n",
    "\n",
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "### 1.1 Tweepy setup\n",
    "I installed tweepy onto the conda environment created at the beginning of class: `conda install tweepy`. This is required to be able to use Twitter API v2 via Python. The `btoken` variable below represents the \"bearer token\" --a secret key that ties my personal application to a tweepy client. It has been removed prior to submission of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "\n",
    "#from twitter_authentication import btoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authenticate this application\n",
    "btoken = \"AAAAAAAAAAAAAAAAAAAAAO8DWQEAAAAA6PZNjSLspN5BxUQeD%2FtDqiGdPLk%3D8qZRtLqE07yOmuPTiy9jnNvGKI16YyM1QgvRR4wvIVoY6Tq9uX\"\n",
    "client = tweepy.Client(btoken, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Obtaining training data\n",
    "#### Context\n",
    "The training data I obtained is based on interactions in the time frame of a specific tweet posted by user @Aishalqahtani. The tweet is in Arabic, but in this tweet, Aisha disclosed her name and picture for the first time after years of being anonymous while living in Qatar. She posted this after seeking asylum in the UK and subsequently received a litany of responses in suppport of and criticizing her actions. The code below retrieves  metadata tied to that specific tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(data=<Tweet id=1218892822599950343 text=Ø³Ù„Ú¤Ø§Ø¯ÙˆØ± Ù‡ÙŠ Ø¹Ø§Ø¦Ø´Ø© Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠØŒ Ù‚Ø·Ø±ÙŠØ©ØŒ Ù…Ø­Ø¨Ø© Ù„ÙˆØ·Ù†ÙŠØŒ ÙˆÙ„ÙƒÙ† Ø£Ù…Ø¶ÙŠØª Ù¢Ù¢ Ø³Ù†Ø© ØªØ­Øª Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù‚Ø§Ù…Ø¹Ø© Ù„Ù„Ù…Ø±Ø£Ø© ÙÙŠ Ù‚Ø·Ø±ØŒ ÙˆØ§Ù„ØªÙŠ ØªØ¹Ø·ÙŠ ÙƒÙ„ Ø§Ù„ØªÙÙˆÙŠØ¶ Ù„Ø°ÙƒØ± Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©ØŒ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„ØªÙŠ ØªØ¯Ù‡Ø³ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†ÙØ§Øª ÙˆØªÙƒØ±Ù‡Ù‡Ù… Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø§Ø²Ù„ Ø¹Ù† Ø­Ù‚ÙˆÙ‚Ù‡Ù…ØŒ Ø§Ù‚Ù Ù‡Ù†Ø§ Ø¨Ø¹Ø¯ Ø§Ù† Ù†Ø¬ÙŠØª Ø¨Ø°Ø§ØªÙŠ Ù…Ù† ÙƒÙ„ Ø°Ù„ÙƒØŒ Ù„Ø£ØªØ­Ø¯Ø« Ø¹Ù† ØªØ¬Ø±Ø¨ØªÙŠ ÙˆØªØ¬Ø±Ø¨Ø© ØºÙŠØ±ÙŠ Ù…Ù† Ø§Ù„Ù†Ø³Ø§Ø¡. https://t.co/XT1urKj3jX>, includes={}, errors=[], meta={})\n"
     ]
    }
   ],
   "source": [
    "origin_id = \"1218892822599950343\"\n",
    "initial_data = client.get_tweet(origin_id, tweet_fields=['geo','referenced_tweets'])\n",
    "print(initial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweepy queries\n",
    "Using the time frame of the above tweet, I queried all tweets in that time frame that were replies or quote tweets of the user @aishalqahtani and stored the responses in `aisha_tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1q/n1dh88bn32vg_dkhg718dqnm0000gn/T/ipykernel_35091/1406439837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Querying replies and retweets to Aisha's 'tweet of independence'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0maisha_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m for response in tweepy.Paginator(client.search_all_tweets, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                  \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'to:aishalqahtani OR retweets_of:aishalqahtani'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                  \u001b[0muser_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'username'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'profile_image_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Querying replies and retweets to Aisha's 'tweet of independence'\n",
    "aisha_tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = 'to:aishalqahtani OR retweets_of:aishalqahtani',\n",
    "                                 user_fields = ['username', 'name', 'location', 'profile_image_url'],\n",
    "                                 tweet_fields = ['id','created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2020-01-19T06:00:00Z',\n",
    "                                 end_time = '2020-01-30T00:00:00Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    aisha_tweets.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aisha_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1q/n1dh88bn32vg_dkhg718dqnm0000gn/T/ipykernel_35091/3452693604.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example response tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maisha_tweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aisha_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "# Example response tweet\n",
    "aisha_tweets[10].data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting responses to dataframe\n",
    "Responses returned above are a complex multi-level data structure, so I created a function `to_dataframe()` so that it could be used for converting both training and test responses to data frames. The function body was obtained from this Twitter API v2 tutorial: <https://www.youtube.com/watch?v=rQEsIs9LERM>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_dataframe(responses: list): \n",
    "    result = []\n",
    "    user_dict = {}\n",
    "    # Loop through each response object\n",
    "    for response in responses:\n",
    "        # Take all of the users, and put them into a dictionary of dictionaries with the info we want to keep\n",
    "        for user in response.includes['users']:\n",
    "            user_dict[user.id] = {'username': user.username, \n",
    "                                  'name': user.name,\n",
    "                                  'profile_image_url': user.profile_image_url,\n",
    "                                  'location': user.location\n",
    "                                 }\n",
    "        for tweet in response.data:\n",
    "            # For each tweet, find the author's information\n",
    "            author_info = user_dict[tweet.author_id]\n",
    "            # Put all of the information we want to keep in a single dictionary for each tweet\n",
    "            result.append({'author_id': tweet.author_id, \n",
    "                           'username': author_info['username'],\n",
    "                           'name': author_info['name'],\n",
    "                           'author_location': author_info['location'],\n",
    "                           'text': tweet.text,\n",
    "                           'created_at': tweet.created_at,\n",
    "                           'retweets': tweet.public_metrics['retweet_count'],\n",
    "                           'replies': tweet.public_metrics['reply_count'],\n",
    "                           'likes': tweet.public_metrics['like_count'],\n",
    "                           'quote_count': tweet.public_metrics['quote_count']\n",
    "                          })\n",
    "\n",
    "    # Change this list of dictionaries into a dataframe\n",
    "    df = pd.DataFrame(result)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisha_reaction_df = to_dataframe(aisha_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>author_location</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216698138125271041</td>\n",
       "      <td>Genat99952881</td>\n",
       "      <td>Genat</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @sa_vadorr: Ù‡Ù†Ø§Ùƒ ÙØªÙŠØ§Øª ÙŠØªØ¹Ø±Ø¶Ù† Ù„Ù„Ø¶Ø±Ø¨ ÙˆØ§Ù„Ø§Ø¶Ø·Ù‡...</td>\n",
       "      <td>2020-01-29 23:04:47+00:00</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147036773</td>\n",
       "      <td>ArabianSaluki</td>\n",
       "      <td>Arabian Saluki</td>\n",
       "      <td>Riyadh, Saudi Arabia</td>\n",
       "      <td>RT @sa_vadorr: Ø·Ø¨Ø¹Ø§ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ø­Ø§Ù„ÙŠØ§ Ø¹Ù„Ù‰ ÙˆØ¶Ø¹...</td>\n",
       "      <td>2020-01-29 22:42:08+00:00</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147036773</td>\n",
       "      <td>ArabianSaluki</td>\n",
       "      <td>Arabian Saluki</td>\n",
       "      <td>Riyadh, Saudi Arabia</td>\n",
       "      <td>RT @sa_vadorr: ÙŠØ§ Ø¹ÙŠÙ†ÙŠ!ØŒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø§Ù„Ø§Ù† Ø§Ù†Ù‡ Ø¹Ù†Ø¯Ù…Ø§...</td>\n",
       "      <td>2020-01-29 22:39:53+00:00</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17024104</td>\n",
       "      <td>innosinz</td>\n",
       "      <td>Nicole Deniese Harris</td>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>@sa_vadorr 100% right, I covered not knowing i...</td>\n",
       "      <td>2020-01-29 22:08:39+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541397323</td>\n",
       "      <td>Critic_man</td>\n",
       "      <td>Ù†Ø§ØµØ±</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @sa_vadorr: Ø³Ù„Ú¤Ø§Ø¯ÙˆØ± Ù‡ÙŠ Ø¹Ø§Ø¦Ø´Ø© Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠØŒ Ù‚Ø·Ø±ÙŠ...</td>\n",
       "      <td>2020-01-29 21:06:45+00:00</td>\n",
       "      <td>1735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>953150634865430528</td>\n",
       "      <td>naah1980</td>\n",
       "      <td>Ù†Ù€Ù€Ø§Ù‡Ù€Ù€Ø¯</td>\n",
       "      <td>None</td>\n",
       "      <td>@sa_vadorr ÙŠØ§Ø´Ù…Ø§ØªØª Ø§Ø¨Ù„Ù‡ Ø·Ø§Ø²Ù‡ ÙÙŠÙ†Ø§ ğŸ˜‚ğŸ˜‚ğŸ˜‚</td>\n",
       "      <td>2020-01-19 13:31:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>2911674320</td>\n",
       "      <td>AlyafieHanan</td>\n",
       "      <td>â„ Ø­Ù†Ø§Ù† Ø§Ù„ÙŠØ§ÙØ¹ÙŠ</td>\n",
       "      <td>Ø®Ø§Ø±Ø¬Ù Ø§Ù„Ø³Ù‘Ø±Ù’Ø¨</td>\n",
       "      <td>RT @sa_vadorr: Ø¬Ø±ÙŠØ¯Ø© Ø§Ù„Ø±Ø§ÙŠØ© Ø§Ø«Ø§Ø±Øª Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…ØŒ...</td>\n",
       "      <td>2020-01-19 13:19:54+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>1209870499284697088</td>\n",
       "      <td>keyalrumaihi</td>\n",
       "      <td>keyalrumaihiğŸ‡¶ğŸ‡¦</td>\n",
       "      <td>Doha, Qatar</td>\n",
       "      <td>@sa_vadorr Ø¨Ø¹Ø¯ Ø§ØªØ°Ù…ÙˆÙ† ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ø¯ Ø°Ù… ÙˆÙ„Ø³Ø§Ù†ÙƒÙ… Ø·ÙˆÙŠ...</td>\n",
       "      <td>2020-01-19 11:58:23+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>1086235403710054400</td>\n",
       "      <td>Ayshalkubaisi1</td>\n",
       "      <td>Ayshalkubaisi_</td>\n",
       "      <td>None</td>\n",
       "      <td>@sa_vadorr Ø¹ÙŠØ´ÙŠ Ø§Ù†Ø³Ø§Ù†ÙŠØªÚ† Ø§Ù„ØºÙŠØ± Ø³ÙˆÙŠØ© Ù…Ø¹ Ù†ÙØ³Ú† Ù„Ø§...</td>\n",
       "      <td>2020-01-19 11:46:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>1086235403710054400</td>\n",
       "      <td>Ayshalkubaisi1</td>\n",
       "      <td>Ayshalkubaisi_</td>\n",
       "      <td>None</td>\n",
       "      <td>@sa_vadorr Ø§Ù„Ø¯Ø¹ÙˆØ© ØªØ±Ø¯ Ù„ØµØ§Ø­Ø¨Ù‡Ø§ ØŒ ÙˆØ§Ù†ØªÙŠ Ø´Ù†Ùˆ Ù…ÙˆÙ‚Ù...</td>\n",
       "      <td>2020-01-19 11:34:05+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6402 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author_id        username                   name  \\\n",
       "0     1216698138125271041   Genat99952881                  Genat   \n",
       "1               147036773   ArabianSaluki         Arabian Saluki   \n",
       "2               147036773   ArabianSaluki         Arabian Saluki   \n",
       "3                17024104        innosinz  Nicole Deniese Harris   \n",
       "4               541397323      Critic_man                   Ù†Ø§ØµØ±   \n",
       "...                   ...             ...                    ...   \n",
       "6397   953150634865430528        naah1980               Ù†Ù€Ù€Ø§Ù‡Ù€Ù€Ø¯   \n",
       "6398           2911674320    AlyafieHanan         â„ Ø­Ù†Ø§Ù† Ø§Ù„ÙŠØ§ÙØ¹ÙŠ   \n",
       "6399  1209870499284697088    keyalrumaihi         keyalrumaihiğŸ‡¶ğŸ‡¦   \n",
       "6400  1086235403710054400  Ayshalkubaisi1         Ayshalkubaisi_   \n",
       "6401  1086235403710054400  Ayshalkubaisi1         Ayshalkubaisi_   \n",
       "\n",
       "           author_location                                               text  \\\n",
       "0                     None  RT @sa_vadorr: Ù‡Ù†Ø§Ùƒ ÙØªÙŠØ§Øª ÙŠØªØ¹Ø±Ø¶Ù† Ù„Ù„Ø¶Ø±Ø¨ ÙˆØ§Ù„Ø§Ø¶Ø·Ù‡...   \n",
       "1     Riyadh, Saudi Arabia  RT @sa_vadorr: Ø·Ø¨Ø¹Ø§ Ù‚Ù†Ø§Ø© Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ø­Ø§Ù„ÙŠØ§ Ø¹Ù„Ù‰ ÙˆØ¶Ø¹...   \n",
       "2     Riyadh, Saudi Arabia  RT @sa_vadorr: ÙŠØ§ Ø¹ÙŠÙ†ÙŠ!ØŒ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø§Ù„Ø§Ù† Ø§Ù†Ù‡ Ø¹Ù†Ø¯Ù…Ø§...   \n",
       "3            Virginia, USA  @sa_vadorr 100% right, I covered not knowing i...   \n",
       "4                     None  RT @sa_vadorr: Ø³Ù„Ú¤Ø§Ø¯ÙˆØ± Ù‡ÙŠ Ø¹Ø§Ø¦Ø´Ø© Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠØŒ Ù‚Ø·Ø±ÙŠ...   \n",
       "...                    ...                                                ...   \n",
       "6397                  None              @sa_vadorr ÙŠØ§Ø´Ù…Ø§ØªØª Ø§Ø¨Ù„Ù‡ Ø·Ø§Ø²Ù‡ ÙÙŠÙ†Ø§ ğŸ˜‚ğŸ˜‚ğŸ˜‚   \n",
       "6398         Ø®Ø§Ø±Ø¬Ù Ø§Ù„Ø³Ù‘Ø±Ù’Ø¨  RT @sa_vadorr: Ø¬Ø±ÙŠØ¯Ø© Ø§Ù„Ø±Ø§ÙŠØ© Ø§Ø«Ø§Ø±Øª Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…ØŒ...   \n",
       "6399           Doha, Qatar  @sa_vadorr Ø¨Ø¹Ø¯ Ø§ØªØ°Ù…ÙˆÙ† ÙÙŠ Ø§Ù„Ø¨Ù„Ø§Ø¯ Ø°Ù… ÙˆÙ„Ø³Ø§Ù†ÙƒÙ… Ø·ÙˆÙŠ...   \n",
       "6400                  None  @sa_vadorr Ø¹ÙŠØ´ÙŠ Ø§Ù†Ø³Ø§Ù†ÙŠØªÚ† Ø§Ù„ØºÙŠØ± Ø³ÙˆÙŠØ© Ù…Ø¹ Ù†ÙØ³Ú† Ù„Ø§...   \n",
       "6401                  None  @sa_vadorr Ø§Ù„Ø¯Ø¹ÙˆØ© ØªØ±Ø¯ Ù„ØµØ§Ø­Ø¨Ù‡Ø§ ØŒ ÙˆØ§Ù†ØªÙŠ Ø´Ù†Ùˆ Ù…ÙˆÙ‚Ù...   \n",
       "\n",
       "                    created_at  retweets  replies  likes  quote_count  \n",
       "0    2020-01-29 23:04:47+00:00        95        0      0            0  \n",
       "1    2020-01-29 22:42:08+00:00       182        0      0            0  \n",
       "2    2020-01-29 22:39:53+00:00        77        0      0            0  \n",
       "3    2020-01-29 22:08:39+00:00         0        0      0            0  \n",
       "4    2020-01-29 21:06:45+00:00      1735        0      0            0  \n",
       "...                        ...       ...      ...    ...          ...  \n",
       "6397 2020-01-19 13:31:49+00:00         0        0      1            0  \n",
       "6398 2020-01-19 13:19:54+00:00        20        0      0            0  \n",
       "6399 2020-01-19 11:58:23+00:00         0        0      0            0  \n",
       "6400 2020-01-19 11:46:27+00:00         0        0      0            0  \n",
       "6401 2020-01-19 11:34:05+00:00         0        1      1            0  \n",
       "\n",
       "[6402 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aisha_reaction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisha_reaction_df.to_csv('aisha_interactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Obtaining test data\n",
    "The method used to obtain test data is the same as training data, however, I chose a more recent incident with a different user, @noofalmaadeed, and obtained interactions within a shorter time frame (2-3 weeks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "noof_tweets = []\n",
    "for response in tweepy.Paginator(client.search_all_tweets, \n",
    "                                 query = 'to:noofalmaadeed OR retweets_of:noofalmaadeed',\n",
    "                                 user_fields = ['username', 'name', 'location', 'profile_image_url'],\n",
    "                                 tweet_fields = ['id','created_at', 'geo', 'public_metrics', 'text'],\n",
    "                                 expansions = 'author_id',\n",
    "                                 start_time = '2021-10-11T00:00:00Z',\n",
    "                                 end_time = '2021-10-30T00:00:00Z',\n",
    "                              max_results=500):\n",
    "    time.sleep(1)\n",
    "    noof_tweets.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "noof_reaction_df = to_dataframe(noof_tweets)\n",
    "noof_reaction_df.to_csv('noof_interactions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data cleaning\n",
    "### 2.1 Removing duplicate retweets\n",
    "There were several duplicate retweets listed as separate datasets, so I took measures to remove them using the drop_duplicates() function in `pandas`. I did this for both training and test and test CSV files.\n",
    "\n",
    "* Initial number of training tweets: 6401\n",
    "\n",
    "* Initial number of test tweets: 637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "df = pd.read_csv('training_duplicates.csv', \n",
    "                usecols=['text']).drop_duplicates(keep=False).reset_index()\n",
    "df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "df = pd.read_csv('test_duplicates.csv', \n",
    "                usecols=['text']).drop_duplicates(keep=False).reset_index()\n",
    "df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Offline CSV restructuring\n",
    "When I retrieved the tweets using the twitter API client, I specified several meta data that were interesting to me and seemed like they might be relevant. However, this meta data was removed for this particular project as I am only analyzing the text data in the tweets for the time being. \n",
    "\n",
    "Steps taken offline:\n",
    "* Removed non-text data (e.g. user location, name, etc) as it is irrelevant to this project. \n",
    "* Removed the old index column\n",
    "* Removed header\n",
    "\n",
    "After steps **2.1** and **2.2**, I ended up with:\n",
    "* Training tweets: 3243\n",
    "* Test tweets: 341"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Annotation\n",
    "For this project, annotation was a requirement for a number of reasons. First, there were no similar datasets that were labeled due to the niche nature of the project. Second, The tweets of interest were both in English and Arabic as both languages are used quite frequently in the geographic region I am studying. But more than that, the Arabic used is not classic Arabic, rather a specific dialect unique to that region, so correct annotations can only be administered by someone who understands them both. The alternative would be to cut out a significant portion of the dataset, but for this study (or an extension of it), both languages need to be taken into account.\n",
    "\n",
    "### 3.1 Label description\n",
    "Offline, I added a column for the label in both `training.csv` and `test.csv`.\n",
    "I used the following annotations to label tweets:\n",
    "* 1 for supportive sentiment\n",
    "* -1 for opposing or invalidating sentiment\n",
    "* 0 for irrelevant, neutral or ambiguous tweets \n",
    "\n",
    "### 3.2 Annotation results:\n",
    "The goal was to end up with $1000$ training data points, however, due to time constraints, I managed $816$ (negative and positive). Including zeroes, total annotations are $1515$.\n",
    "\n",
    "| Dataset  |  1  | -1  | 0    |\n",
    "| -------- |-----|-----|------|\n",
    "| Training | 231 | 585 | 699  |\n",
    "| Test     | 75  | 65  | 186  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dataset refinement\n",
    "Due to the ambiguous nature of the zero-labeled tweets, I've decided to remove them from consideration (in the following code block). I also remove @mentions from the tweet contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100% right, I covered not knowing it was my c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ÙƒÙ…ÙŠØ© Ø·Ø§Ù‚Ù‡ Ø³Ù„Ø¨ÙŠÙ‡ ÙÙŠ ÙˆÙŠÙ‡Ø¬ ÙˆÙƒÙ„Ø§Ù…Ø¬..Ù…Ø³ÙƒÙŠÙ†Ù‡ Ø§Ù†ØªÙŠ Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ÙƒØ°Ø¨ Ù…Ù† Ù‚Ø§Ù„ Ø¥Ù† Ø§Ù„ØªØ¹Ø±ÙŠ ÙŠØ²ÙŠØ¯ Ø§Ù„Ù…Ø±Ø£Ø© Ø¬Ù…Ø§Ù„Ø§ https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ Ù„Ø§ ÙŠØ¨Ù„Ø§Ù†Ø§ Ø¨Ø³ ÙˆÙŠØ³ØªØ±Ù†Ø§ ÙØ§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø§Ø®Ø±Ø©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(ÙŠÙØ§ Ø£ÙÙŠÙÙ‘Ù‡ÙØ§ Ø§Ù„Ù†ÙÙ‘Ø¨ÙÙŠÙÙ‘ Ù‚ÙÙ„ Ù„ÙÙ‘Ø£ÙØ²Ù’ÙˆÙØ§Ø¬ÙÙƒÙ Ùˆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>3237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>you gorgeous mashallah âœ¨âœ¨âœ¨ thank you for shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>3238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§Ù…Ø§ Ø§Ù„Ø§Ù† ÙØ£Ø³ØªØ·ÙŠØ¹ Ø§Ù† Ø§ÙƒÙˆÙ† ØµÙˆØª Ù„Ù„ÙˆØ§ØªÙŠ ÙŠØ±Ø¯Ù† Ø§Ù† ÙŠØ´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>3239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ÙŠØ¬Ø¨ Ø§Ù† ÙŠØ¹ÙŠ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø¨ÙƒÙ…ÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø³Ù„ÙˆØ¨Ø© Ù…Ù† Ø§Ù„Ù…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>3242</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ø¹ÙŠØ´ÙŠ Ø§Ù†Ø³Ø§Ù†ÙŠØªÚ† Ø§Ù„ØºÙŠØ± Ø³ÙˆÙŠØ© Ù…Ø¹ Ù†ÙØ³Ú† Ù„Ø§ØªØ­Ø±Ø¶ÙŠÙ† Ø§Ù„Ø¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>3243</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ø§Ù„Ø¯Ø¹ÙˆØ© ØªØ±Ø¯ Ù„ØµØ§Ø­Ø¨Ù‡Ø§ ØŒ ÙˆØ§Ù†ØªÙŠ Ø´Ù†Ùˆ Ù…ÙˆÙ‚ÙÚ† ÙŠÙˆÙ… Ù‚Ø§Ù„Ùˆ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1                                                  2\n",
       "0        0  1.0   100% right, I covered not knowing it was my c...\n",
       "1        1 -1.0   ÙƒÙ…ÙŠØ© Ø·Ø§Ù‚Ù‡ Ø³Ù„Ø¨ÙŠÙ‡ ÙÙŠ ÙˆÙŠÙ‡Ø¬ ÙˆÙƒÙ„Ø§Ù…Ø¬..Ù…Ø³ÙƒÙŠÙ†Ù‡ Ø§Ù†ØªÙŠ Ùˆ...\n",
       "2        3 -1.0   ÙƒØ°Ø¨ Ù…Ù† Ù‚Ø§Ù„ Ø¥Ù† Ø§Ù„ØªØ¹Ø±ÙŠ ÙŠØ²ÙŠØ¯ Ø§Ù„Ù…Ø±Ø£Ø© Ø¬Ù…Ø§Ù„Ø§ https:...\n",
       "3        4 -1.0          Ø§Ù„Ù„Ù‡ Ù„Ø§ ÙŠØ¨Ù„Ø§Ù†Ø§ Ø¨Ø³ ÙˆÙŠØ³ØªØ±Ù†Ø§ ÙØ§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø§Ø®Ø±Ø©\n",
       "4        5 -1.0   (ÙŠÙØ§ Ø£ÙÙŠÙÙ‘Ù‡ÙØ§ Ø§Ù„Ù†ÙÙ‘Ø¨ÙÙŠÙÙ‘ Ù‚ÙÙ„ Ù„ÙÙ‘Ø£ÙØ²Ù’ÙˆÙØ§Ø¬ÙÙƒÙ Ùˆ...\n",
       "...    ...  ...                                                ...\n",
       "2515  3237  1.0   you gorgeous mashallah âœ¨âœ¨âœ¨ thank you for shar...\n",
       "2516  3238  1.0  Ø§Ù…Ø§ Ø§Ù„Ø§Ù† ÙØ£Ø³ØªØ·ÙŠØ¹ Ø§Ù† Ø§ÙƒÙˆÙ† ØµÙˆØª Ù„Ù„ÙˆØ§ØªÙŠ ÙŠØ±Ø¯Ù† Ø§Ù† ÙŠØ´...\n",
       "2517  3239  1.0  ÙŠØ¬Ø¨ Ø§Ù† ÙŠØ¹ÙŠ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø¨ÙƒÙ…ÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ø³Ù„ÙˆØ¨Ø© Ù…Ù† Ø§Ù„Ù…...\n",
       "2518  3242 -1.0   Ø¹ÙŠØ´ÙŠ Ø§Ù†Ø³Ø§Ù†ÙŠØªÚ† Ø§Ù„ØºÙŠØ± Ø³ÙˆÙŠØ© Ù…Ø¹ Ù†ÙØ³Ú† Ù„Ø§ØªØ­Ø±Ø¶ÙŠÙ† Ø§Ù„Ø¨...\n",
       "2519  3243 -1.0   Ø§Ù„Ø¯Ø¹ÙˆØ© ØªØ±Ø¯ Ù„ØµØ§Ø­Ø¨Ù‡Ø§ ØŒ ÙˆØ§Ù†ØªÙŠ Ø´Ù†Ùˆ Ù…ÙˆÙ‚ÙÚ† ÙŠÙˆÙ… Ù‚Ø§Ù„Ùˆ...\n",
       "\n",
       "[813 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv', header=None)\n",
    "# remove nonlabeled rows\n",
    "train_df = train_df.dropna()  \n",
    "\n",
    "# remove rows with 0 labels \n",
    "train_df = train_df.loc[train_df[1] != 0] \n",
    "\n",
    "# remove mentions\n",
    "train_df[2] = train_df[2].replace(r'@.*?(?=\\s)', '', regex=True)\n",
    "\n",
    "train_df\n",
    "\n",
    "#train_df.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø´Ù„ÙˆÙ† ÙˆØ«Ù‚ØªÙŠğŸ’”ØŸ ÙªÙŠØ§Ø±Ø¨ Ø§Ù†Ø¬ Ø¨Ø®ÙŠØ±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ÙˆØ§ÙŠØ¯ Ù…ÙØªÙ„Ù…Ù‡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ù‡Ù„ Ø§Ù†ØªÙŠ Ø¨Ø¬ÙŠØ± Ø­Ù†Ø¢ Ù…Ø¹Ø§Ùƒ ÙˆØ§ Ù†Ø­Ø¨Ùƒ ÙƒØ«ÙŠØ± ğŸ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Still worried for uâ€¦ #ÙˆÙŠÙ†_Ù†ÙˆÙ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stay safe remember be strong! We love u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙˆÙ…Ø§Ø¹Ù„ÙŠÙƒ Ø´Ø± Ø§Ù† Ø´Ø§Ø¡Ø§Ù„Ù„Ù‡ Ø§Ù†ØªÙŠ ÙÙŠ Ø¨Ù„Ø¯ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>323</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ø§ØªÙ…Ù†Ù‰ Ø§Ù† Ø§Ù„Ù„ÙŠ ÙŠØ¹Ø±Ù Ù†ÙˆÙ ÙŠØªØ±ÙƒÙ‡Ø§ ÙÙŠ Ø­Ø§Ù„Ù‡Ø§ \\nØªØ¹ÙŠØ´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ø§Ù†Øª Ø§Ù‚ÙˆÙ‰ Ù…Ù† Ù…Ø§ ØªØ¹ØªÙ‚Ø¯ÙŠÙ† ÙŠØ§ Ù†ÙˆÙ\\nØ±ØºÙ… Ù…Ø§ ØªØªØ­ÙØ¸ÙŠÙ†...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Ù…Ø§ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø«Ø§Ù„ÙŠ Ø§Ù„Ø§ Ø¨ÙŠØª ÙˆØ§Ù„Ø¯ÙŠØ¬\\nÙ‚Ø±ÙŠ Ù…ÙƒØ§Ù†Ùƒ Ùˆ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ù†ØªÙ…Ù†Ù‰ Ø§Ù† Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø®ØªØµØ© ØªØ£Ø®Ø° Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ù…Ø­Ù…Ù„ Ø§Ù„...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1                                                  2\n",
       "0      0  1.0                        Ø´Ù„ÙˆÙ† ÙˆØ«Ù‚ØªÙŠğŸ’”ØŸ ÙªÙŠØ§Ø±Ø¨ Ø§Ù†Ø¬ Ø¨Ø®ÙŠØ±\n",
       "2      2 -1.0                                        ÙˆØ§ÙŠØ¯ Ù…ÙØªÙ„Ù…Ù‡\n",
       "3      3  1.0               Ù‡Ù„ Ø§Ù†ØªÙŠ Ø¨Ø¬ÙŠØ± Ø­Ù†Ø¢ Ù…Ø¹Ø§Ùƒ ÙˆØ§ Ù†Ø­Ø¨Ùƒ ÙƒØ«ÙŠØ± ğŸ’\n",
       "4      4  1.0                      Still worried for uâ€¦ #ÙˆÙŠÙ†_Ù†ÙˆÙ\n",
       "11    11  1.0            Stay safe remember be strong! We love u\n",
       "..   ...  ...                                                ...\n",
       "319  320  1.0   Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ùƒ ÙˆÙ…Ø§Ø¹Ù„ÙŠÙƒ Ø´Ø± Ø§Ù† Ø´Ø§Ø¡Ø§Ù„Ù„Ù‡ Ø§Ù†ØªÙŠ ÙÙŠ Ø¨Ù„Ø¯ ...\n",
       "322  323 -1.0   Ø§ØªÙ…Ù†Ù‰ Ø§Ù† Ø§Ù„Ù„ÙŠ ÙŠØ¹Ø±Ù Ù†ÙˆÙ ÙŠØªØ±ÙƒÙ‡Ø§ ÙÙŠ Ø­Ø§Ù„Ù‡Ø§ \\nØªØ¹ÙŠØ´...\n",
       "323  331  1.0   Ø§Ù†Øª Ø§Ù‚ÙˆÙ‰ Ù…Ù† Ù…Ø§ ØªØ¹ØªÙ‚Ø¯ÙŠÙ† ÙŠØ§ Ù†ÙˆÙ\\nØ±ØºÙ… Ù…Ø§ ØªØªØ­ÙØ¸ÙŠÙ†...\n",
       "324  333 -1.0    Ù…Ø§ÙÙŠ Ù…ÙƒØ§Ù† Ù…Ø«Ø§Ù„ÙŠ Ø§Ù„Ø§ Ø¨ÙŠØª ÙˆØ§Ù„Ø¯ÙŠØ¬\\nÙ‚Ø±ÙŠ Ù…ÙƒØ§Ù†Ùƒ Ùˆ ...\n",
       "325  335  1.0   Ù†ØªÙ…Ù†Ù‰ Ø§Ù† Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ù…Ø®ØªØµØ© ØªØ£Ø®Ø° Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ù…Ø­Ù…Ù„ Ø§Ù„...\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv', header=None)\n",
    "\n",
    "# remove nonlabeled rows\n",
    "test_df = test_df.dropna()  \n",
    "\n",
    "# remove rows with 0 labels \n",
    "test_df = test_df.loc[test_df[1] != 0] \n",
    "\n",
    "# remove mentions\n",
    "test_df[2] = test_df[2].replace(r'@.*?(?=\\s)', '', regex=True)\n",
    "\n",
    "test_df\n",
    "\n",
    "#test_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df.iloc[0:, 1].values\n",
    "text_train = train_df.iloc[0:, 2].values\n",
    "\n",
    "Y_test = test_df.iloc[0:, 1].values\n",
    "text_test = test_df.iloc[0:, 2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Detect language \n",
    "The following code blocks create separate dataframes for English and Arabic tweets because the tokenization processes are different for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Feature prep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "arabic_punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "stopwords_list = stopwords.words('arabic')\n",
    "stopwords_list += stopwords.words('english')\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def preprocess(text: str):\n",
    "    text = text.lower()   \n",
    "     #Convert www.* or https?://* to \" \"\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',text)\n",
    "    \n",
    "    #Replace #word with word\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "\n",
    "    # remove punctuations\n",
    "    text = remove_punctuations(text)\n",
    "    \n",
    "    \n",
    "    # remove repeated letters\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)\n",
    "    \n",
    "    # remove arabic and english stop words\n",
    "    splt = text.split()\n",
    "    for i,word in enumerate(splt):\n",
    "        if word in stopwords_list:\n",
    "            splt[i]=splt[i].replace(word,'')\n",
    "            \n",
    "    text = ' '.join(splt)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÙŠØ§Ø¹Ø²ØªÙŠ  Ø­Ø³Ø¨Ù†Ø§ Ø§Ù„Ù„Ù‡ ÙˆÙ†Ø¹Ù… Ø§Ù„ÙˆÙƒÙŠÙ„   ØºØ±Ø± Ø¨Ø¯ÙŠÙ†Ùƒ ÙˆÙÙƒØ±Ùƒ Ø§Ù„Ù„Ù‡ ÙŠÙ„Ø·Ù Ø¨Ø­Ø§Ù„Ùƒ ÙˆØ­Ø§Ù„ Ø§Ù…Ùƒ ÙˆØ£Ù‡Ù„Ùƒ ÙˆØ§Ø­Ø¨Ø§Ø¨Ùƒ Ø§ØªØ¹Ø¨ØªÙŠÙ‡Ù… Ø°Ø¨Ø­ØªÙ‡Ù… ÙˆÙ‡Ù… Ø£Ø­ÙŠØ§Ø¡ Ø§Ù„Ù„Ù‡ ÙŠÙ„Ø³Ø·   Ø³Ø§Ø¹Ø¯Ùƒ ÙˆØºØ±Ø±  Ø¹Ø°Ø§Ø¨ Ø§Ù„Ù‡ÙˆÙ†  Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø¢Ø®Ø±Ø©'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing preprocessing function \n",
    "preprocess(text_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Vectorization\n",
    "#### TF-IDF\n",
    "I decided to first test the TF-IDF vectorizer due to its nature of rating more important words appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect_tf = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', ngram_range=(1, 2))\n",
    "X_train_tfidf = vect_tf.fit_transform(preprocess(tweet) for tweet in text_train)\n",
    "X_test_tfidf = vect_tf.transform(preprocess(tweet) for tweet in text_test)\n",
    "\n",
    "# print(vect.get_feature_names())\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer\n",
    "I wanted to compare the TF-IDF vectorization algorithm with a simpler implementation, the CountVectorizer, and see how that affects accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect_ct = CountVectorizer(strip_accents='unicode', ngram_range=(1,2))\n",
    "X_train_ct = vect_ct.fit_transform(preprocess(tweet) for tweet in text_train)\n",
    "X_test_ct = vect_ct.transform(preprocess(tweet) for tweet in text_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# class Tokenizer:\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         self.tokenizer_dict: Dict = {}\n",
    "#         self.tokenize_length = 0\n",
    "        \n",
    "#     def fit(self, array_strings, split_param=\" \"):\n",
    "#         \"\"\" creates tokenize dictionary \"\"\"\n",
    "#         counter = 1\n",
    "#         for string in array_strings:\n",
    "#             words = string.split(split_param)\n",
    "#             for word_i in words:\n",
    "#                 if word_i not in self.tokenizer_dict:\n",
    "#                     self.tokenizer_dict[word_i] = counter\n",
    "#                     counter += 1\n",
    "#         # make a tokenizer length\n",
    "#         self.tokenize_length = counter\n",
    "        \n",
    "#     def transform(self, array_strings, split_param=\" \", count=None):\n",
    "#         \"\"\" returns a vector \"\"\"\n",
    "#         tokenized_matrix = []\n",
    "#         for string in array_strings:\n",
    "#             string_vec = np.zeros((self.tokenize_length))\n",
    "#             words = string.split(split_param)\n",
    "#             for word_i in words:\n",
    "#                 if word_i in self.tokenizer_dict:\n",
    "#                     index = self.tokenizer_dict[word_i]\n",
    "#                     if count:\n",
    "#                         string_vec[index] += 1\n",
    "#                     else: \n",
    "#                         string_vec[index] = 1\n",
    "#             tokenized_matrix.append(string_vec)\n",
    "#         return tokenized_matrix\n",
    "    \n",
    "#     def fit_transform(self, array_strings):\n",
    "#         self.fit(array_strings)\n",
    "#         return self.transform(array_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = Tokenizer()\n",
    "vect.fit(preprocess(tweet) for tweet in text_train)\n",
    "X_train = vect.transform(preprocess(tweet) for tweet in text_train)\n",
    "X_test = vect.transform(preprocess(tweet) for tweet in text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classifier setup & hyperparameter tuning\n",
    "### 5.1 Model 1: logistic regression\n",
    "Hyperparameter tuning with 10-fold grid search cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "be\n",
      "ÙŠÙƒÙˆÙ†\n",
      "Ø§Ù„Ù…Ø±Ø£Ø©\n",
      "Ù„Ùƒ\n",
      "Ø¬Ù…ÙŠÙ„Ø©\n",
      "you\n",
      "of\n",
      "Ø¹Ù‚Ø¨Ø§Ù„ÙŠ\n",
      "Ù…Ø¹Ùƒ\n",
      "Ø­Ø¨ÙŠØ¨ØªÙŠ\n",
      "ÙˆÙ„ÙƒÙ†\n",
      "ÙŠØ­ÙØ¸Ùƒ\n",
      "Ø´Ø±\n",
      "proud\n",
      "ÙŠØ­ÙØ¸Ø¬\n",
      "Ù‚Ù„Ø¨ÙŠ\n",
      "â¤ï¸\n",
      "brave\n",
      "Ø²Ø§Ù„Øª\n",
      "rt\n",
      "Ø³Ø¹ÙŠØ¯Ø©\n",
      "ÙƒÙˆÙ†ÙŠ\n",
      "Ù…Ø¹Ø§Ùƒ\n",
      "Ø§ØªÙ…Ù†Ù‰\n",
      "Ø­Ø±Ø©\n",
      "Ø±Ø¨ÙŠ\n",
      "Ø­ÙŠØ§ØªÙƒ\n",
      "Ù…ÙˆÙÙ‚Ù‡\n",
      "Ø§Ù„Ø­ÙŠØ§Ø©\n",
      "ÙŠØ³Ù‡Ù„\n",
      "ÙˆÙŠØ­ÙØ¸Ø¬\n",
      "Ù…Ø¨Ø±ÙˆÙƒ\n",
      "Ø¹Ù‚Ø¨Ø§Ù„\n",
      "ÙØ®Ø±\n"
     ]
    }
   ],
   "source": [
    "base_classifier = LogisticRegression(penalty='l2', tol=1e-2, max_iter=500, random_state=123)\n",
    "\n",
    "base_classifier.fit(X_train, Y_train)\n",
    "base_classifier.score(X_test, Y_test)\n",
    "\n",
    "# get the top coefficeints and the index of those (say top 10; both neg and pos top 10)\n",
    "coeff = [(ind, val) for ind, val in enumerate(base_classifier.coef_[0])]\n",
    "top_10 = list(filter(lambda a: a[1] > 0.5, coeff))\n",
    "# bottom_10 = \n",
    "\n",
    "top_10_ind = [i[0] for i in top_10]\n",
    "# from the top 10, find what those words are\n",
    "\n",
    "for key, val in vect.tokenizer_dict.items():\n",
    "    if val in top_10_ind:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': {'LogisticRegression': 0.8188405797101449,\n",
       "  'AdaBoostClassifier': 0.6811594202898551,\n",
       "  'KNN': 0.5579710144927537,\n",
       "  'SVM': 0.959409594095941}}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression\n",
      "adaboost\n",
      "KNN\n",
      "SVM\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_dict(data, title, x_label):\n",
    "    \"\"\"\n",
    "    creates bar plot for a given result dictionary\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,2,1])\n",
    "    parameters = data.keys()\n",
    "    tool_results = get_results(data)\n",
    "    \n",
    "    # plotting\n",
    "    width = 0\n",
    "    X = np.arange(len(data.keys()))\n",
    "    colors = ['r', 'b', 'black', 'pink', 'yellow', 'orange']\n",
    "    counter = 0\n",
    "    width_increment = 1/(len(tool_results.keys())+2)\n",
    "    for tool, results in tool_results.items():\n",
    "        ax.bar(X + width, results, color = colors[counter], width = width_increment, label=tool, edgecolor='black')\n",
    "        width += width_increment\n",
    "        counter += 1\n",
    "    plt.legend()\n",
    "    plt.title(title, size=20)\n",
    "    plt.ylabel(\"Acccuracy\", size=20)\n",
    "    plt.xlabel(x_label, size=20)\n",
    "    ax.set_xticks(X+ (width_increment * 0.5 * len(tool_results.keys())))\n",
    "    ax.set_xticklabels(parameters, size=20)\n",
    "\n",
    "def get_results(data):\n",
    "    \"\"\"\n",
    "    gets a tool specific results dictionary\n",
    "    \"\"\"\n",
    "    tool_results = {}\n",
    "    for result, result_dict in data.items():\n",
    "        for tool, accuracy in result_dict.items():\n",
    "            if tool == 'FFNN': accuracy = accuracy[1]\n",
    "            accuracy = round(accuracy, 3)\n",
    "            if tool in tool_results:\n",
    "                tool_results[tool].append(accuracy)\n",
    "            else:\n",
    "                tool_results[tool] = [accuracy]\n",
    "                \n",
    "    return tool_results\n",
    "\n",
    "\"\"\"\n",
    "PLOTTING RESULTS\n",
    "\"\"\"\n",
    "results = test_models(X_test, Y_test, X_train, Y_train)\n",
    "results = {'results' : results}\n",
    "plot_dict(results, \"testing different models\", \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, models\n",
    "from numpy import loadtxt\n",
    "\n",
    "def test_models(test_x, test_y, train_x, train_y):\n",
    "    score_dict = {'LogisticRegression': 0,\n",
    "                  'AdaBoostClassifier' : 0,\n",
    "                  'KNN' : 0,\n",
    "                  'SVM' : 0,\n",
    "                  #'FFNN' : 0\n",
    "                 }\n",
    "    \n",
    "    # Logistic Regression\n",
    "    print(\"logistic regression\")\n",
    "    LogisticRegression_i = LogisticRegression(random_state=0, max_iter=1000).fit(train_x, train_y)\n",
    "    score_dict['LogisticRegression'] = LogisticRegression_i.score(test_x, test_y) \n",
    "    \n",
    "    # Adaboost\n",
    "    print(\"adaboost\")\n",
    "    AdaBoostClassifier_i = AdaBoostClassifier(n_estimators=100, random_state=0).fit(train_x, train_y)\n",
    "    score_dict['AdaBoostClassifier'] = AdaBoostClassifier_i.score(test_x, test_y)\n",
    "    \n",
    "    # KNN\n",
    "    print(\"KNN\")\n",
    "    KNN = KNeighborsClassifier(n_neighbors=2).fit(train_x, train_y)\n",
    "    score_dict['KNN'] = KNN.score(test_x, test_y)  \n",
    "    \n",
    "    # SVM\n",
    "    print(\"SVM\")\n",
    "    svc = svm.SVC().fit(train_x, train_y)\n",
    "    score_dict['SVM'] = svc.score(train_x, train_y)    \n",
    "\n",
    "    # FFNN\n",
    "#     model = models.Sequential()\n",
    "#     model.add(layers.Dense(len(train_x[0]), input_dim=len(train_x[0]), activation='relu'))\n",
    "#     model.add(layers.Dense(500, activation='relu'))\n",
    "#     model.add(layers.Dense(1, activation='sigmoid'))\n",
    "#     batch_size = 1\n",
    "#     epochs = 20\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     train_x = np.array(train_x)\n",
    "#     train_y = np.array(train_y)\n",
    "#     test_x, test_y = np.array(test_x), np.array(test_y)\n",
    "#     model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, validation_data=(test_x, test_y))\n",
    "#     score_dict['FFNN'] = model.evaluate(test_x, test_y)\n",
    "    \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1q/n1dh88bn32vg_dkhg718dqnm0000gn/T/ipykernel_35091/2803884902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgs_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(gs_classifier.get_params())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'processes'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1407\u001b[0m                                \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    756\u001b[0m             iprint = [-1, 50, 1, 100, 101][\n\u001b[1;32m    757\u001b[0m                 np.searchsorted(np.array([0, 1, 2, 3]), verbose)]\n\u001b[0;32m--> 758\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# LBFGSB is sent 'old-style' bounds, 'new-style' bounds are required by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# approx_derivative and ScalarFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mnew_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_bound_to_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;31m# check bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.8/site-packages/scipy/optimize/_constraints.py\u001b[0m in \u001b[0;36mold_bound_to_new\u001b[0;34m(bounds)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# Convert occurrences of None to -inf or inf, and replace occurrences of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "base_classifier = LogisticRegression(multi_class='multinomial', solver='lbfgs', tol=1e-2, max_iter=500, random_state=123)\n",
    "\n",
    "params = [{'C':[100, 10, 1.0, 0.1, 0.01]}]\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=10)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "#print(gs_classifier.get_params())\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Model 2: SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter settings: {'C': 100, 'kernel': 'linear'}\n",
      "Validation accuracy: 0.840033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "base_classifier = SVC(random_state=123)\n",
    "\n",
    "params = [{'kernel':['linear','rbf'], 'C': [100, 10, 1.0, 0.1, 0.01]}]\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=10)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter settings: {'min_samples_split': 2, 'n_estimators': 200}\n",
      "Validation accuracy: 0.828907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_classifier = RandomForestClassifier(random_state=123)\n",
    "\n",
    "params = [{'n_estimators':[50, 100, 200, 300], 'min_samples_split': [2, 3, 6]}]\n",
    "\n",
    "gs_classifier = GridSearchCV(base_classifier, params, cv=10)\n",
    "gs_classifier.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best parameter settings:\", gs_classifier.best_params_)\n",
    "print(\"Validation accuracy: %0.6f\" % gs_classifier.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
